// Lexer for the Shotgun compiler
//
// The lexer reads source code character by character and produces tokens.
// It handles whitespace, comments, string interpolation, and multi-character operators.

uses: shotgun.token

// Lexer state
Lexer :: struct {
    source str
    pos int
    line int
    col int
    file str
    keywords Keywords
    nesting int  // Track nesting depth for significant newlines
}

// Create a new lexer
fn new_lexer(str source, str file) Lexer {
    return Lexer {
        source: source,
        pos: 0,
        line: 1,
        col: 1,
        file: file,
        keywords: make_keywords(),
        nesting: 0
    }
}

// Check if we're at end of file
Lexer :: is_eof(self) bool {
    return self.pos >= self.source.len()
}

// Peek at current character without advancing (returns 0 at EOF)
Lexer :: peek(self) int {
    if self.is_eof() {
        return 0
    }
    return self.source.at(self.pos)
}

// Peek at next character (one ahead)
Lexer :: peek_next(self) int {
    if self.pos + 1 >= self.source.len() {
        return 0
    }
    return self.source.at(self.pos + 1)
}

// Advance position by one character
Lexer :: advance(self) int {
    ch := self.peek()
    self.pos = self.pos + 1
    if ch == 10 {  // newline
        self.line = self.line + 1
        self.col = 1
    } else {
        self.col = self.col + 1
    }
    return ch
}

// Get current location
Lexer :: location(self) Location {
    return Location { line: self.line, col: self.col, file: self.file }
}

// Create a token at the current location
Lexer :: make_token(self, Token tok) LocatedToken {
    return LocatedToken { token: tok, location: self.location() }
}

// Check if character is whitespace (space=32, tab=9)
fn is_whitespace(int ch) bool {
    return ch == 32 || ch == 9
}

// Check if character is newline
fn is_newline(int ch) bool {
    return ch == 10 || ch == 13
}

// Check if character is a digit (0-9: 48-57)
fn is_digit(int ch) bool {
    return ch >= 48 && ch <= 57
}

// Check if character is a lowercase letter (a-z: 97-122)
fn is_lower(int ch) bool {
    return ch >= 97 && ch <= 122
}

// Check if character is an uppercase letter (A-Z: 65-90)
fn is_upper(int ch) bool {
    return ch >= 65 && ch <= 90
}

// Check if character is a letter
fn is_letter(int ch) bool {
    return is_lower(ch) || is_upper(ch)
}

// Check if character can start an identifier (lowercase or underscore)
fn is_ident_start(int ch) bool {
    return is_lower(ch) || ch == 95
}

// Check if character can start a type identifier (uppercase)
fn is_type_start(int ch) bool {
    return is_upper(ch)
}

// Check if character can be in an identifier
fn is_ident_char(int ch) bool {
    return is_letter(ch) || is_digit(ch) || ch == 95
}

// Skip whitespace (but not newlines)
Lexer :: skip_whitespace(self) {
    while !self.is_eof() && is_whitespace(self.peek()) {
        self.advance()
    }
}

// Skip a line comment (// to end of line)
Lexer :: skip_line_comment(self) {
    while !self.is_eof() && !is_newline(self.peek()) {
        self.advance()
    }
}

// Read an identifier or keyword
Lexer :: read_ident(self) str {
    start := self.pos
    while !self.is_eof() && is_ident_char(self.peek()) {
        self.advance()
    }
    return self.source.slice(start, self.pos)
}

// Read a type identifier (starts with uppercase)
Lexer :: read_type_ident(self) str {
    start := self.pos
    while !self.is_eof() && is_ident_char(self.peek()) {
        self.advance()
    }
    return self.source.slice(start, self.pos)
}

// Read an integer (returns the string, caller converts)
Lexer :: read_number(self) Token {
    start := self.pos
    while !self.is_eof() && is_digit(self.peek()) {
        self.advance()
    }

    // Check for float
    if self.peek() == 46 && is_digit(self.peek_next()) {  // '.'
        self.advance()  // consume the dot
        while !self.is_eof() && is_digit(self.peek()) {
            self.advance()
        }
        num_str := self.source.slice(start, self.pos)
        return Token.TkFloat { value: parse_float(num_str) }
    }

    num_str := self.source.slice(start, self.pos)
    return Token.TkInt { value: parse_int(num_str) }
}

// Read a string literal (handles escape sequences and interpolation)
Lexer :: read_string(self) Token {
    self.advance()  // consume opening quote
    result := ""

    while !self.is_eof() && self.peek() != 34 {  // not closing quote
        ch := self.peek()

        if ch == 92 {  // backslash - escape sequence
            self.advance()
            next := self.peek()
            if next == 110 {  // \n
                result = result + "\n"
                self.advance()
            } else if next == 114 {  // \r
                result = result + "\r"
                self.advance()
            } else if next == 116 {  // \t
                result = result + "\t"
                self.advance()
            } else if next == 92 {  // \\
                result = result + "\\"
                self.advance()
            } else if next == 34 {  // \"
                result = result + "\""
                self.advance()
            } else if next == 123 {  // \{ - escaped brace
                result = result + "\\" + "\{"
                self.advance()
            } else {
                // Unknown escape, keep as-is
                result = result + "\\"
            }
        } else if ch == 123 {  // { - start of interpolation
            // Read until matching }
            result = result + "\{"
            self.advance()
            depth := 1
            while !self.is_eof() && depth > 0 {
                c := self.peek()
                if c == 123 {
                    depth = depth + 1
                } else if c == 125 {
                    depth = depth - 1
                }
                if depth > 0 {
                    result = result + char_to_str(c)
                    self.advance()
                }
            }
            result = result + "\}"
            if !self.is_eof() {
                self.advance()  // consume closing }
            }
        } else {
            result = result + char_to_str(ch)
            self.advance()
        }
    }

    if !self.is_eof() {
        self.advance()  // consume closing quote
    }

    return Token.TkString { value: result }
}

// Read a character literal 'a', '\n', etc.
Lexer :: read_char(self) Token {
    self.advance()  // consume opening quote

    if self.is_eof() {
        return Token.TkError { msg: "unterminated character literal" }
    }

    ch := self.peek()
    result_char := '\0'

    if ch == 92 {  // backslash - escape sequence
        self.advance()
        next := self.peek()
        if next == 110 {  // \n
            result_char = '\n'
        } else if next == 114 {  // \r
            result_char = '\r'
        } else if next == 116 {  // \t
            result_char = '\t'
        } else if next == 92 {  // \\
            result_char = '\\'
        } else if next == 39 {  // \'
            result_char = '\''
        } else if next == 48 {  // \0
            result_char = '\0'
        } else {
            return Token.TkError { msg: "unknown escape sequence in character literal" }
        }
        self.advance()
    } else if ch == 39 {  // empty char literal ''
        return Token.TkError { msg: "empty character literal" }
    } else {
        // Regular character - convert int to char
        result_char = chr(ch)
        self.advance()
    }

    // Expect closing quote
    if self.peek() != 39 {
        return Token.TkError { msg: "unterminated character literal" }
    }
    self.advance()  // consume closing quote

    return Token.TkChar { value: result_char }
}

// Get the next token
Lexer :: next_token(self) LocatedToken {
    // Skip whitespace
    self.skip_whitespace()

    // Handle newlines
    if is_newline(self.peek()) {
        loc := self.location()
        self.advance()
        // Skip \r\n as single newline
        if self.peek() == 10 {
            self.advance()
        }
        // Only emit newline token if not inside brackets/parens/braces
        if self.nesting == 0 {
            return LocatedToken { token: Token.TkNewline{}, location: loc }
        }
        return self.next_token()  // Skip newline inside nesting
    }

    // Check for EOF
    if self.is_eof() {
        return self.make_token(Token.TkEof{})
    }

    // Check for line comment
    if self.peek() == 47 && self.peek_next() == 47 {  // //
        self.skip_line_comment()
        return self.next_token()
    }

    loc := self.location()
    ch := self.peek()

    // Identifiers and keywords
    if is_ident_start(ch) {
        ident := self.read_ident()
        if ident == "_" {
            return LocatedToken { token: Token.TkUnderscore{}, location: loc }
        }
        if self.keywords.is_keyword(ident) {
            return LocatedToken { token: Token.TkKeyword { name: ident }, location: loc }
        }
        return LocatedToken { token: Token.TkIdent { name: ident }, location: loc }
    }

    // Type identifiers
    if is_type_start(ch) {
        ident := self.read_type_ident()
        return LocatedToken { token: Token.TkTypeIdent { name: ident }, location: loc }
    }

    // Numbers
    if is_digit(ch) {
        tok := self.read_number()
        return LocatedToken { token: tok, location: loc }
    }

    // Strings
    if ch == 34 {  // "
        tok := self.read_string()
        return LocatedToken { token: tok, location: loc }
    }

    // Character literals
    if ch == 39 {  // '
        tok := self.read_char()
        return LocatedToken { token: tok, location: loc }
    }

    // Multi-character operators and punctuation
    self.advance()

    // Two-character operators
    next := self.peek()

    if ch == 58 {  // :
        if next == 58 {  // ::
            self.advance()
            return LocatedToken { token: Token.TkColonColon{}, location: loc }
        }
        if next == 61 {  // :=
            self.advance()
            return LocatedToken { token: Token.TkColonEq{}, location: loc }
        }
        return LocatedToken { token: Token.TkColon{}, location: loc }
    }

    if ch == 45 {  // -
        if next == 62 {  // ->
            self.advance()
            return LocatedToken { token: Token.TkArrow{}, location: loc }
        }
        if next == 61 {  // -=
            self.advance()
            return LocatedToken { token: Token.TkMinusEq{}, location: loc }
        }
        return LocatedToken { token: Token.TkMinus{}, location: loc }
    }

    if ch == 61 {  // =
        if next == 61 {  // ==
            self.advance()
            return LocatedToken { token: Token.TkEqEq{}, location: loc }
        }
        return LocatedToken { token: Token.TkEq{}, location: loc }
    }

    if ch == 33 {  // !
        if next == 61 {  // !=
            self.advance()
            return LocatedToken { token: Token.TkNeq{}, location: loc }
        }
        return LocatedToken { token: Token.TkBang{}, location: loc }
    }

    if ch == 60 {  // <
        if next == 61 {  // <=
            self.advance()
            return LocatedToken { token: Token.TkLte{}, location: loc }
        }
        return LocatedToken { token: Token.TkLt{}, location: loc }
    }

    if ch == 62 {  // >
        if next == 61 {  // >=
            self.advance()
            return LocatedToken { token: Token.TkGte{}, location: loc }
        }
        return LocatedToken { token: Token.TkGt{}, location: loc }
    }

    if ch == 43 {  // +
        if next == 61 {  // +=
            self.advance()
            return LocatedToken { token: Token.TkPlusEq{}, location: loc }
        }
        return LocatedToken { token: Token.TkPlus{}, location: loc }
    }

    if ch == 42 {  // *
        if next == 61 {  // *=
            self.advance()
            return LocatedToken { token: Token.TkStarEq{}, location: loc }
        }
        return LocatedToken { token: Token.TkStar{}, location: loc }
    }

    if ch == 47 {  // /
        if next == 61 {  // /=
            self.advance()
            return LocatedToken { token: Token.TkSlashEq{}, location: loc }
        }
        return LocatedToken { token: Token.TkSlash{}, location: loc }
    }

    if ch == 38 {  // &
        if next == 38 {  // &&
            self.advance()
            return LocatedToken { token: Token.TkAndAnd{}, location: loc }
        }
        return LocatedToken { token: Token.TkError { msg: "unexpected '&'" }, location: loc }
    }

    if ch == 124 {  // |
        if next == 124 {  // ||
            self.advance()
            return LocatedToken { token: Token.TkOrOr{}, location: loc }
        }
        return LocatedToken { token: Token.TkError { msg: "unexpected '|'" }, location: loc }
    }

    // Single-character tokens with nesting tracking
    if ch == 40 {  // (
        self.nesting = self.nesting + 1
        return LocatedToken { token: Token.TkLParen{}, location: loc }
    }
    if ch == 41 {  // )
        self.nesting = self.nesting - 1
        return LocatedToken { token: Token.TkRParen{}, location: loc }
    }
    if ch == 123 {  // {
        self.nesting = self.nesting + 1
        return LocatedToken { token: Token.TkLBrace{}, location: loc }
    }
    if ch == 125 {  // }
        self.nesting = self.nesting - 1
        return LocatedToken { token: Token.TkRBrace{}, location: loc }
    }
    if ch == 91 {  // [
        self.nesting = self.nesting + 1
        return LocatedToken { token: Token.TkLBracket{}, location: loc }
    }
    if ch == 93 {  // ]
        self.nesting = self.nesting - 1
        return LocatedToken { token: Token.TkRBracket{}, location: loc }
    }

    // Other single-character tokens
    if ch == 44 {  // ,
        return LocatedToken { token: Token.TkComma{}, location: loc }
    }
    if ch == 46 {  // .
        return LocatedToken { token: Token.TkDot{}, location: loc }
    }
    if ch == 37 {  // %
        return LocatedToken { token: Token.TkPercent{}, location: loc }
    }
    if ch == 63 {  // ?
        return LocatedToken { token: Token.TkQuestion{}, location: loc }
    }

    // Unknown character
    return LocatedToken {
        token: Token.TkError { msg: "unexpected character" },
        location: loc
    }
}

// Helper: convert ASCII code to single-char string
fn char_to_str(int ch) str {
    return chr(ch).to_string()
}

// Parse integer from string
fn parse_int(str s) int {
    result := 0
    i := 0
    while i < s.len() {
        ch := s.at(i)
        if ch >= 48 && ch <= 57 {
            result = result * 10 + (ch - 48)
        }
        i = i + 1
    }
    return result
}

// Parse float from string (simple implementation)
fn parse_float(str s) f64 {
    // Find the dot
    dot_pos := s.find(".")
    if dot_pos < 0 {
        return 0.0  // No dot, shouldn't happen
    }

    int_part := s.slice(0, dot_pos)
    frac_part := s.slice(dot_pos + 1, s.len())

    int_val := parse_int(int_part)
    frac_val := parse_int(frac_part)

    // Calculate divisor based on fraction length
    divisor := 1.0
    i := 0
    while i < frac_part.len() {
        divisor = divisor * 10.0
        i = i + 1
    }

    // Convert to float for the result
    f64 int_f = int_val * 1.0
    f64 frac_f = frac_val * 1.0
    return int_f + frac_f / divisor
}
